{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4주차 과제_정시은.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sieunjeong/jse_gjai_pre/blob/master/4%EC%A3%BC%EC%B0%A8_%EA%B3%BC%EC%A0%9C_%EC%A0%95%EC%8B%9C%EC%9D%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxkL6PjwsI6L",
        "colab_type": "text"
      },
      "source": [
        "# 4주차 과제\n",
        "- 용어 정리\n",
        "- 딥러닝 강의 클론 코딩\n",
        "- 딥러닝 순전파 & 역전파 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixEtDe6_uGgI",
        "colab_type": "text"
      },
      "source": [
        "## 1. 용어 정리\n",
        "\n",
        "다음 제시된 단어의 정의(설명)를 정리하여 작성 하세요.\n",
        "\n",
        "* 2문장 이상 작성 해 주세요. \n",
        "* 주제(단어)와 크게 벗어나지만 않는다면 정답처리 됩니다.\n",
        "* 강의 뿐 아니라 기타 레퍼런스를 참고하여 작성하셔도 됩니다. (기타 레퍼런스를 참고하신 경우, 해당 레퍼런스를 정리하여 하단에 작성해 주세요.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lfwat8eurKZ",
        "colab_type": "text"
      },
      "source": [
        "__(예시)__\n",
        "### 심층 신경망\n",
        ": 입력층과 출력층 사이에 여러 개의 은닉층들로 이뤄진 인공신경망이다. 심층 신경망은 일반적으로 인공신경망과 마찬가지로 복잡한 비선형 관계들을 모델링 할 수 있다. 신층신경망의 목적은 분류 및 수치예측을 하기 위함이고 이미지 트레이닝이나 문자인식과 같은 분야에서 매우 유용하게 쓰이고 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8YJNKG_v65A",
        "colab_type": "text"
      },
      "source": [
        "### MCP 뉴런\n",
        ": AI를 설계하기 위해 생물학적 뇌가 동작하는 방식을 이해하려는 시도로 1943년 워런 맥컬록과 월터 피츠가 처음으로 발표한 간소화 된 뇌의 뉴런 개념이다. 뉴런들은 뇌의 신경 세포와 서로 연결되어 화학적, 전기적 신호를 처리하고 전달하는데 관여한다. 이런 신경 세포를 이진 출력을 내는 간단한 논리 회로로 표현 했다. 초창기 머신 러닝이며, 맥컬록-피츠 뉴런이라 한다.\n",
        "\n",
        "### 퍼셉트론\n",
        ": 입력을 받아서 계산 후, 출력을 나타내는 구조로 이뤄진다. MCP뉴런 모델을 기반으로 1957년 프랭크 로젠 블랫이 퍼셉트론 학습 개념을 처음 발표했으며, 퍼셉트론 규칙에서 자동으로 최적의 가중치를 학습하는 알고리즘을 제안했다. 이 가중치는 뉴런의 출력 신호를 낼지 말지 결정하기 위해 입력 특성에 곱하는 계수가 된다. 단층 퍼셉트론과 다층 퍼셉트론이 있다. 몇 년 후 제시된 다층 퍼셉트론은 은닉층을 가지고 XOR 연산 문제를 해결 가능하며, 딥러닝의 뿌리가 되는 기법이다.\n",
        "\n",
        "### 역전파\n",
        ": 뉴런의 가중치를 효율적으로 조정하기 위하여 거꾸로 무엇인가를 전파하는 방식으로 제프리 힌튼이 역전파 알고리즘을 제시하며, 다층 퍼셉트론의 문제를 해결했다. 출력 값과 지도 데이터 사이에서 생기는 오차를 이용해 출력층에서 입력층 쪽으로 가중치를 조정한다. 역전파를 활용하면 신경망이 출력 값부터 차례로 이전 노드값이 정해지게 된다. 신경망이 깊어질수로 기울기 소멸 문제가 발생해 학습이 잘 진행되지 않으나 제프리 힌튼의 ReLU활성화 함수를 활용하여 어느정도 해결할 수 있다\n",
        "\n",
        "### 강화학습\n",
        ": 보상을 최대화하는 의사결정 전략, 즉 순차적인 행동을 알아가는 방법이다. 에이전트라는 존재가 환경과 상호 작용하며, 환경에는 보상이라는 기준이 있어 다양한 시행착오를 겪어가며, 보상을 최대화 하는 방법으로 학습을 진행한다. 에이전트는 현재 스텝에서 받았던 보상으로 부터 에피소드가 끝날 때까지 받았던 보상들을 더한 것을 정보로 이용하고, 이런 정보를 기록, 업데이트 하는 과정을 반복한다. 강화학습은 다양한 시행착오를 통해 학습이 가능하며, 비교적 명확한 보상을 설정할 수 있는 문제를 해결하는데 사용 된다.\n",
        "\n",
        "### 과적합\n",
        ": 모델에 훈련 데이터를 과하게 학습시키는 것을 말한다. 모델이 학습 데이터를 불필요할 정도로 과하게 암기하여 훈련 데이터에 포함된 노이즈까지 학습한 상태라고 해석할 수 있다. 모델이 과적합되면, 훈련 데이터에 대한 정확도는 높아도 새로운 데이터에서는 제대로 동작하지 않는다. 실제 데이터에 오차나 손실 함수가 커지게 되고, 일반화의 성능이 떨어지게 된다. 과적합은 층이 너무 많거나 변수가 복잡할 때, 데이터 양이 너무 적어 데이터의 특정 패턴까지 학습한 경우 발생한다. 과적합을 막는 방법으로는 데이터 증식, 모델복잡도/변수 줄이기, 가중치 규제 적용, 드롭아웃이 있다.\n",
        "* 모두의 딥러닝\n",
        "* 딥러닝의 정석:텐서플로와 최신기법으로 배우는 딥러닝 알고리즘 설계\n",
        "* 딥러닝을 이용한 자연어 처리 입문\n",
        "* yongku.tistory.com/entry/딥러닝과-머신러닝-과적합Overfitting\n",
        "* Dive into Deep Learning\n",
        "\n",
        "### 차원의 저주\n",
        ": 데이터의 차원이 증가할수록 해당 공간의 크기가 기하급수적으로 증가하므로 필요한 데이터의 개수가 기하급수적으로 증가하게 되는 어려움을 표현한 용어이다. 차원이 늘어날수록, 같은 비율과 공간을 채우기 위해 변수 1개당 필요한 데이터의 양이 급격히 증가한다. 알고리즘의 연산 속도가 떨어지거나 목표 함수를 올바르게 학습하지 못하게 된다. 데이터 밀도가 줄어 예측력이 떨어지고, 데이터의 양이 부족해져 노이즈를 포함해 과적합이 발생하게 된다. 차원이 증가할수록 데이터 셋 내 거리의 개념이 부정확해지고, 연산의 복잡도가 증가한다. 차원의 저주 극복 방법에는 차원의 축소, 차원 단순화, 주성분분석(PCA)등이 있다.\n",
        "* 하둡과 스파크를 활용한 실용 데이터 과학\n",
        "* tSL the Science Life 의 빅데이터:큰 용량의 역습-차원이 저주\n",
        "* Kevin Murphy Machine Learning Statistic _ www.slideshare.net/ssuser67b08e/kevin-murphy-machine-learning-statistic\n",
        "* [통계]차원의 저주와 KNN알고리즘 _ greatjoy.tistory.com/56\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-zfFXLCy6jD",
        "colab_type": "text"
      },
      "source": [
        "## 2. 딥러닝 강의 클론 코딩\n",
        "\n",
        "####__퍼셉트론 구조 구현하기__ \n",
        "딥러닝 강의(__딥러닝 원리[1] 3:15 ~ 5:15 부분__)를 보고 코드를 따라 치며 출력 결과를 만드세요.\n",
        " \n",
        "\n",
        "* 하나의 코드셀에 해당 코드를 한번에 다 적어서 실행해주세요 (__그렇게 하지 않을 경우, 아래 이미지와 같은 출력값이 나오지 않을 수 있습니다__)\n",
        "\n",
        "*__주의!__ 실제로 코딩해서 출력해보면 강의에 나온 출력 결과와 다르게 나옵니다!!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcc5mzI9oZ7r",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0cceeed0-0235-4b0f-af88-0b8c377d5b4b%2F_2020-06-09__9.35.23.png?table=block&id=88fd8912-9356-49a4-9fda-a1a63fe96ea9&width=2870&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr0HVRk8fOom",
        "colab_type": "text"
      },
      "source": [
        "## 3. 딥러닝 순전파 & 역전파 계산\n",
        "\n",
        "딥러닝 강의(__딥러닝 원리[2] 0:55 ~ 4:32 부분__)에 나오는 순전파 & 역전파 계산에 대한 문제 입니다.\n",
        "\n",
        "해당 영상과 다음 이미지를 참고하여 다음 2가지 물음에 답하세요.\n",
        "\n",
        "\n",
        "(1) 학습률이 0.2 일 경우 출력층의 노드값\n",
        "\n",
        "(2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpwPFWhOUzww",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff54dfd45-92ec-44ae-9616-6949d2484a45%2F_2020-06-10__5.22.03.png?table=block&id=ee05da89-3ceb-4ad9-a2d3-c9f68d24d1d9&width=3580&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2OVY7w5U3CI",
        "colab_type": "text"
      },
      "source": [
        "## (1) 학습률이 0.2 일 경우 출력층의 노드값 : 1.6\n",
        "## (2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은? : 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgavfvqiWxBU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "c83e9f21-c01c-4672-fa99-e8e059e98b22"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(2020)\n",
        "x = 1\n",
        "y = 0\n",
        "w = tf.random.normal([1], 0, 1)\n",
        "\n",
        "import math\n",
        "def sigmoid(x):\n",
        "    return 1/(1 + math.exp(-x))\n",
        "\n",
        "output = sigmoid(x*w)\n",
        "print(output)\n",
        "\n",
        "for i in range(1000):\n",
        "    output = sigmoid(x*w)\n",
        "    error = y - output\n",
        "    w = w + x * 0.1 * error\n",
        "\n",
        "    if i % 100 == 99:\n",
        "        print(\"학습 횟수:\",i,\"Error:\",error,\"예측 결과:\",output)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.47477188589261\n",
            "학습 횟수: 99 Error: -0.10010598284299604 예측 결과: 0.10010598284299604\n",
            "학습 횟수: 199 Error: -0.05178399422833116 예측 결과: 0.05178399422833116\n",
            "학습 횟수: 299 Error: -0.034590451977903586 예측 결과: 0.034590451977903586\n",
            "학습 횟수: 399 Error: -0.02588962752851373 예측 결과: 0.02588962752851373\n",
            "학습 횟수: 499 Error: -0.020658699939863617 예측 결과: 0.020658699939863617\n",
            "학습 횟수: 599 Error: -0.017174253993457355 예측 결과: 0.017174253993457355\n",
            "학습 횟수: 699 Error: -0.014689506449480992 예측 결과: 0.014689506449480992\n",
            "학습 횟수: 799 Error: -0.012829497265431342 예측 결과: 0.012829497265431342\n",
            "학습 횟수: 899 Error: -0.011385568271837804 예측 결과: 0.011385568271837804\n",
            "학습 횟수: 999 Error: -0.010232493309882492 예측 결과: 0.010232493309882492\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}